{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "logs = spark.read.parquet(\"hdfs://devenv/user/spark/spark_mllib_101/ec_web_logs_analysis/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagging places the users go frequently for each device and output to MySQL\n",
    "all_device_ids = logs.select(\"device_id\") \\\n",
    "    .distinct() \\\n",
    "    .rdd.map(lambda row: row[0]).collect()\n",
    "\n",
    "\n",
    "len_all_device_ids = len(all_device_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len_all_device_ids):\n",
    "    print(\"{}/{} processed.\".format(i,len_all_device_ids))\n",
    "\n",
    "    device_locations = logs.select(\"device_id\", \"lat\", \"lon\")\\\n",
    "        .where(\"device_id = '{}'\".format(all_device_ids[i]))\n",
    "\n",
    "    device_locations = VectorAssembler(inputCols=[\"lat\", \"lon\"],\n",
    "                                       outputCol=\"features\").transform(device_locations)\n",
    "    # Model training\n",
    "    kmeans = KMeans(k=10)\n",
    "    model = kmeans.fit(device_locations)\n",
    "\n",
    "    # Transform the test data using the model to get predictions\n",
    "    predicted_device_locations = model.transform(device_locations)\n",
    "\n",
    "    # Cluster centers and count\n",
    "    device_inferred_location = predicted_device_locations.groupBy(\"device_id\", \"prediction\") \\\n",
    "        .agg(avg(\"lat\").alias(\"avg_lat\"), avg(\"lon\").alias(\"avg_lon\"), count(\"*\").alias(\"lat_lon_count\")) \\\n",
    "        .drop(\"prediction\")\n",
    "\n",
    "    device_inferred_location.persist()\n",
    "\n",
    "    device_inferred_location.show()\n",
    "\n",
    "    device_inferred_location.write.option(\"driver\", \"com.mysql.jdbc.Driver\") \\\n",
    "        .jdbc(\"jdbc:mysql://192.168.186.139:3306\", \"ec_web_logs_analysis.device_inferred_location\",\n",
    "              properties={\"user\": \"spark\", \"password\": \"spark\"}, mode=\"append\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
