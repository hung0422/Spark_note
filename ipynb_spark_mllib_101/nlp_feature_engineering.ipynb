{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, StopWordsRemover, NGram, HashingTF, IDF, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.186.133:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://devenv:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f05871d94d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.186.133:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://devenv:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://devenv:7077 appName=PySparkShell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (0, \"From all sides were heard the footsteps and talk of the infantry, who were walking, driving past, and settling down all around.\"),\n",
    "    (1, \"IIt was no longer, as before, a dark, unseen river flowing through the gloom, but a dark sea swelling and gradually subsiding after a storm.\"),\n",
    "    (2, \"\\\"You don't mind your honor?\\\" he asked Tushin. \\\"I've lost my company, your honor. I don't know where... such bad luck!'\\\"\")],\n",
    "    \"id int, message string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|id |message                                                                                                                                     |\n",
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0  |From all sides were heard the footsteps and talk of the infantry, who were walking, driving past, and settling down all around.             |\n",
      "|1  |IIt was no longer, as before, a dark, unseen river flowing through the gloom, but a dark sea swelling and gradually subsiding after a storm.|\n",
      "|2  |\"You don't mind your honor?\" he asked Tushin. \"I've lost my company, your honor. I don't know where... such bad luck!'\"                     |\n",
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|id |message                                                                                                                                     |words                                                                                                                                                                 |\n",
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0  |From all sides were heard the footsteps and talk of the infantry, who were walking, driving past, and settling down all around.             |[from, all, sides, were, heard, the, footsteps, and, talk, of, the, infantry,, who, were, walking,, driving, past,, and, settling, down, all, around.]                |\n",
      "|1  |IIt was no longer, as before, a dark, unseen river flowing through the gloom, but a dark sea swelling and gradually subsiding after a storm.|[iit, was, no, longer,, as, before,, a, dark,, unseen, river, flowing, through, the, gloom,, but, a, dark, sea, swelling, and, gradually, subsiding, after, a, storm.]|\n",
      "|2  |\"You don't mind your honor?\" he asked Tushin. \"I've lost my company, your honor. I don't know where... such bad luck!'\"                     |[\"you, don't, mind, your, honor?\", he, asked, tushin., \"i've, lost, my, company,, your, honor., i, don't, know, where..., such, bad, luck!'\"]                         |\n",
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#A tokenizer that converts the input string to lowercase and then splits it by white spaces.\n",
    "words = Tokenizer(inputCol=\"message\", outputCol=\"words\").transform(df)\n",
    "words.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|id |message                                                                                                                                     |words                                                                                                                                                            |\n",
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0  |From all sides were heard the footsteps and talk of the infantry, who were walking, driving past, and settling down all around.             |[from, all, sides, were, heard, the, footsteps, and, talk, of, the, infantry, who, were, walking, driving, past, and, settling, down, all, around]               |\n",
      "|1  |IIt was no longer, as before, a dark, unseen river flowing through the gloom, but a dark sea swelling and gradually subsiding after a storm.|[iit, was, no, longer, as, before, a, dark, unseen, river, flowing, through, the, gloom, but, a, dark, sea, swelling, and, gradually, subsiding, after, a, storm]|\n",
      "|2  |\"You don't mind your honor?\" he asked Tushin. \"I've lost my company, your honor. I don't know where... such bad luck!'\"                     |[you, don, t, mind, your, honor, he, asked, tushin, i, ve, lost, my, company, your, honor, i, don, t, know, where, such, bad, luck]                              |\n",
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A regex based tokenizer that extracts tokens either by using the provided regex pattern (in Java dialect) to split the text (default) or repeatedly matching the regex (if gaps is false). Optional parameters also allow filtering tokens using a minimal length. It returns an array of strings that can be empty.\n",
    "words = RegexTokenizer(inputCol=\"message\", outputCol=\"words\", pattern=\"\\\\W+\").transform(df)\n",
    "words.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|id |message                                                                                                                                     |words                                                                                                                                                            |stop_words_removed                                                                                  |\n",
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|0  |From all sides were heard the footsteps and talk of the infantry, who were walking, driving past, and settling down all around.             |[from, all, sides, were, heard, the, footsteps, and, talk, of, the, infantry, who, were, walking, driving, past, and, settling, down, all, around]               |[sides, heard, footsteps, talk, infantry, walking, driving, past, settling, around]                 |\n",
      "|1  |IIt was no longer, as before, a dark, unseen river flowing through the gloom, but a dark sea swelling and gradually subsiding after a storm.|[iit, was, no, longer, as, before, a, dark, unseen, river, flowing, through, the, gloom, but, a, dark, sea, swelling, and, gradually, subsiding, after, a, storm]|[iit, longer, dark, unseen, river, flowing, gloom, dark, sea, swelling, gradually, subsiding, storm]|\n",
      "|2  |\"You don't mind your honor?\" he asked Tushin. \"I've lost my company, your honor. I don't know where... such bad luck!'\"                     |[you, don, t, mind, your, honor, he, asked, tushin, i, ve, lost, my, company, your, honor, i, don, t, know, where, such, bad, luck]                              |[mind, honor, asked, tushin, ve, lost, company, honor, know, bad, luck]                             |\n",
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# StopWordsRemover is feature transformer that filters out stop words from input.\n",
    "stop_words_removed = StopWordsRemover(inputCol=\"words\", outputCol=\"stop_words_removed\").transform(words)\n",
    "stop_words_removed.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|id |message                                                                                                                                     |words                                                                                                                                                            |ngrams                                                                                                                                                                                                                                                                                        |\n",
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0  |From all sides were heard the footsteps and talk of the infantry, who were walking, driving past, and settling down all around.             |[from, all, sides, were, heard, the, footsteps, and, talk, of, the, infantry, who, were, walking, driving, past, and, settling, down, all, around]               |[from all, all sides, sides were, were heard, heard the, the footsteps, footsteps and, and talk, talk of, of the, the infantry, infantry who, who were, were walking, walking driving, driving past, past and, and settling, settling down, down all, all around]                             |\n",
      "|1  |IIt was no longer, as before, a dark, unseen river flowing through the gloom, but a dark sea swelling and gradually subsiding after a storm.|[iit, was, no, longer, as, before, a, dark, unseen, river, flowing, through, the, gloom, but, a, dark, sea, swelling, and, gradually, subsiding, after, a, storm]|[iit was, was no, no longer, longer as, as before, before a, a dark, dark unseen, unseen river, river flowing, flowing through, through the, the gloom, gloom but, but a, a dark, dark sea, sea swelling, swelling and, and gradually, gradually subsiding, subsiding after, after a, a storm]|\n",
      "|2  |\"You don't mind your honor?\" he asked Tushin. \"I've lost my company, your honor. I don't know where... such bad luck!'\"                     |[you, don, t, mind, your, honor, he, asked, tushin, i, ve, lost, my, company, your, honor, i, don, t, know, where, such, bad, luck]                              |[you don, don t, t mind, mind your, your honor, honor he, he asked, asked tushin, tushin i, i ve, ve lost, lost my, my company, company your, your honor, honor i, i don, don t, t know, know where, where such, such bad, bad luck]                                                          |\n",
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ngrams                                                                                                                                                                                                                                                                                        |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[from all, all sides, sides were, were heard, heard the, the footsteps, footsteps and, and talk, talk of, of the, the infantry, infantry who, who were, were walking, walking driving, driving past, past and, and settling, settling down, down all, all around]                             |\n",
      "|[iit was, was no, no longer, longer as, as before, before a, a dark, dark unseen, unseen river, river flowing, flowing through, through the, the gloom, gloom but, but a, a dark, dark sea, sea swelling, swelling and, and gradually, gradually subsiding, subsiding after, after a, a storm]|\n",
      "|[you don, don t, t mind, mind your, your honor, honor he, he asked, asked tushin, tushin i, i ve, ve lost, lost my, my company, company your, your honor, honor i, i don, don t, t know, know where, where such, such bad, bad luck]                                                          |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NGram is a feature transformer that converts the input array of strings into an array of n-grams. Null values in the input array are ignored. It returns an array of n-grams where each n-gram is represented by a space-separated string of words. When the input is empty, an empty array is returned. When the input array length is less than n (number of elements per n-gram), no n-grams are returned.\n",
    "ngram_df = NGram(n=2, inputCol=\"words\", outputCol=\"ngrams\").transform(words)\n",
    "\n",
    "ngram_df.show(truncate=False)\n",
    "ngram_df.select(\"ngrams\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|words                                                                                                                                                            |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[from, all, sides, were, heard, the, footsteps, and, talk, of, the, infantry, who, were, walking, driving, past, and, settling, down, all, around]               |\n",
      "|[iit, was, no, longer, as, before, a, dark, unseen, river, flowing, through, the, gloom, but, a, dark, sea, swelling, and, gradually, subsiding, after, a, storm]|\n",
      "|[you, don, t, mind, your, honor, he, asked, tushin, i, ve, lost, my, company, your, honor, i, don, t, know, where, such, bad, luck]                              |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.[1] It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling.\n",
    "df = words.select(\"words\")\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               words|          hashing_tf|\n",
      "+--------------------+--------------------+\n",
      "|[from, all, sides...|(15,[0,2,3,7,8,10...|\n",
      "|[iit, was, no, lo...|(15,[0,1,2,3,4,5,...|\n",
      "|[you, don, t, min...|(15,[0,2,3,4,5,7,...|\n",
      "+--------------------+--------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|words                                                                                                                                                            |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[from, all, sides, were, heard, the, footsteps, and, talk, of, the, infantry, who, were, walking, driving, past, and, settling, down, all, around]               |\n",
      "|[iit, was, no, longer, as, before, a, dark, unseen, river, flowing, through, the, gloom, but, a, dark, sea, swelling, and, gradually, subsiding, after, a, storm]|\n",
      "|[you, don, t, mind, your, honor, he, asked, tushin, i, ve, lost, my, company, your, honor, i, don, t, know, where, such, bad, luck]                              |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "+-------------------------------------------------------------------------------------------------------+\n",
      "|hashing_tf                                                                                             |\n",
      "+-------------------------------------------------------------------------------------------------------+\n",
      "|(15,[0,2,3,7,8,10,11,12,13,14],[4.0,1.0,2.0,3.0,1.0,1.0,2.0,4.0,3.0,1.0])                              |\n",
      "|(15,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14],[3.0,1.0,1.0,1.0,1.0,3.0,1.0,1.0,1.0,3.0,2.0,1.0,3.0,2.0,1.0])|\n",
      "|(15,[0,2,3,4,5,7,8,9,11,12],[1.0,2.0,2.0,5.0,1.0,4.0,2.0,2.0,3.0,2.0])                                 |\n",
      "+-------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hashing TF is TF with hashing enabled to allow the feature vector to be a set value\n",
    "df_tf = HashingTF(inputCol=\"words\", outputCol=\"hashing_tf\", numFeatures=15).transform(df)\n",
    "\n",
    "df_tf.show()\n",
    "df_tf.select(\"words\").show(truncate=False)\n",
    "df_tf.select(\"hashing_tf\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|               words|          hashing_tf|              tf_idf|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[from, all, sides...|(15,[0,2,3,7,8,10...|(15,[0,2,3,7,8,10...|\n",
      "|[iit, was, no, lo...|(15,[0,1,2,3,4,5,...|(15,[0,1,2,3,4,5,...|\n",
      "|[you, don, t, min...|(15,[0,2,3,4,5,7,...|(15,[0,2,3,4,5,7,...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|words                                                                                                                                                            |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[from, all, sides, were, heard, the, footsteps, and, talk, of, the, infantry, who, were, walking, driving, past, and, settling, down, all, around]               |\n",
      "|[iit, was, no, longer, as, before, a, dark, unseen, river, flowing, through, the, gloom, but, a, dark, sea, swelling, and, gradually, subsiding, after, a, storm]|\n",
      "|[you, don, t, mind, your, honor, he, asked, tushin, i, ve, lost, my, company, your, honor, i, don, t, know, where, such, bad, luck]                              |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "+-------------------------------------------------------------------------------------------------------+\n",
      "|hashing_tf                                                                                             |\n",
      "+-------------------------------------------------------------------------------------------------------+\n",
      "|(15,[0,2,3,7,8,10,11,12,13,14],[4.0,1.0,2.0,3.0,1.0,1.0,2.0,4.0,3.0,1.0])                              |\n",
      "|(15,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14],[3.0,1.0,1.0,1.0,1.0,3.0,1.0,1.0,1.0,3.0,2.0,1.0,3.0,2.0,1.0])|\n",
      "|(15,[0,2,3,4,5,7,8,9,11,12],[1.0,2.0,2.0,5.0,1.0,4.0,2.0,2.0,3.0,2.0])                                 |\n",
      "+-------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|tf_idf                                                                                                                                                                                                                           |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(15,[0,2,3,7,8,10,11,12,13,14],[0.0,0.0,0.0,0.0,0.0,0.28768207245178085,0.0,0.0,0.8630462173553426,0.28768207245178085])                                                                                                         |\n",
      "|(15,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14],[0.0,0.6931471805599453,0.0,0.0,0.28768207245178085,0.8630462173553426,0.6931471805599453,0.0,0.0,0.8630462173553426,0.5753641449035617,0.0,0.0,0.5753641449035617,0.28768207245178085])|\n",
      "|(15,[0,2,3,4,5,7,8,9,11,12],[0.0,0.0,0.0,1.4384103622589042,0.28768207245178085,0.0,0.0,0.5753641449035617,0.0,0.0])                                                                                                             |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# IDF\n",
    "df_tf_idf = IDF(inputCol=\"hashing_tf\", outputCol=\"tf_idf\").fit(df_tf).transform(df_tf)\n",
    "\n",
    "df_tf_idf.show()\n",
    "df_tf_idf.select(\"words\").show(truncate=False)\n",
    "df_tf_idf.select(\"hashing_tf\").show(truncate=False) # Hashing TF\n",
    "df_tf_idf.select(\"tf_idf\").show(truncate=False) # IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|words                                                                                                                                                            |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[from, all, sides, were, heard, the, footsteps, and, talk, of, the, infantry, who, were, walking, driving, past, and, settling, down, all, around]               |\n",
      "|[iit, was, no, longer, as, before, a, dark, unseen, river, flowing, through, the, gloom, but, a, dark, sea, swelling, and, gradually, subsiding, after, a, storm]|\n",
      "|[you, don, t, mind, your, honor, he, asked, tushin, i, ve, lost, my, company, your, honor, i, don, t, know, where, such, bad, luck]                              |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF from CountVectorizer, which is used to extract words and counts from document collection\n",
    "df = words.select(\"words\")\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               words|               tf_cv|\n",
      "+--------------------+--------------------+\n",
      "|[from, all, sides...|(57,[1,2,8,9,11,1...|\n",
      "|[iit, was, no, lo...|(57,[0,1,2,3,12,1...|\n",
      "|[you, don, t, min...|(57,[4,5,6,7,10,1...|\n",
      "+--------------------+--------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|words                                                                                                                                                            |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[from, all, sides, were, heard, the, footsteps, and, talk, of, the, infantry, who, were, walking, driving, past, and, settling, down, all, around]               |\n",
      "|[iit, was, no, longer, as, before, a, dark, unseen, river, flowing, through, the, gloom, but, a, dark, sea, swelling, and, gradually, subsiding, after, a, storm]|\n",
      "|[you, don, t, mind, your, honor, he, asked, tushin, i, ve, lost, my, company, your, honor, i, don, t, know, where, such, bad, luck]                              |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|tf_cv                                                                                                                                                         |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(57,[1,2,8,9,11,13,14,17,18,22,23,25,33,35,38,45,46,49],[2.0,2.0,2.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                            |\n",
      "|(57,[0,1,2,3,12,15,16,20,21,24,27,30,31,34,36,37,42,47,50,54,55,56],[3.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|(57,[4,5,6,7,10,19,26,28,29,32,39,40,41,43,44,48,51,52,53],[2.0,2.0,2.0,2.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                     |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tf_cv = CountVectorizer(inputCol=\"words\", outputCol=\"tf_cv\").fit(df).transform(df)\n",
    "df_tf_cv.show()\n",
    "df_tf_cv.select(\"words\").show(truncate=False)\n",
    "df_tf_cv.select(\"tf_cv\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
